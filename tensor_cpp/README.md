# Tensor C++ Library - Qwen3 Implementation with Parallel Optimizations

é«˜æ€§èƒ½çš„ C++ Tensor åº“ï¼ŒåŒ…å« Qwen3-0.6B æ¨¡å‹çš„å®Œæ•´å®ç°ï¼Œæ”¯æŒ OpenMPã€MPIã€AVX2 ä¼˜åŒ–å’Œ KV Cacheã€‚

## ğŸ¯ ç‰¹æ€§

### æ ¸å¿ƒåŠŸèƒ½
- âœ… **Qwen3-0.6B æ¨¡å‹å®Œæ•´å®ç°**: 28å±‚ Transformer æ¶æ„
- âœ… **KV Cache æ”¯æŒ**: å¤§å¹…æå‡ decode é˜¶æ®µæ€§èƒ½ï¼ˆ1.74x åŠ é€Ÿï¼‰
- âœ… **åˆ†ç»„æŸ¥è¯¢æ³¨æ„åŠ› (GQA)**: ä¼˜åŒ–æ³¨æ„åŠ›æœºåˆ¶
- âœ… **RoPE (æ—‹è½¬ä½ç½®ç¼–ç )**: æ­£ç¡®å®ç°
- âœ… **Safetensors æ ¼å¼**: æ”¯æŒ HuggingFace æ¨¡å‹æƒé‡

### æ€§èƒ½ä¼˜åŒ–
- âš¡ **OpenMP å¹¶è¡Œ**: å¤šçº¿ç¨‹åŠ é€Ÿ
- âš¡ **AVX2 SIMD**: å‘é‡åŒ–è®¡ç®—ï¼ˆ1.6-3.3x åŠ é€Ÿï¼‰
- âš¡ **MPI æ•°æ®å¹¶è¡Œ**: å¤šèŠ‚ç‚¹åˆ†å¸ƒå¼è®­ç»ƒ/æ¨ç†
- âš¡ **å¼ é‡å¹¶è¡Œ**: æ¨¡å‹åˆ‡åˆ†ä¼˜åŒ–

### æ­£ç¡®æ€§ä¿è¯
- âœ… **æ•°å€¼éªŒè¯**: ä¸ PyTorch å®ç°å¯¹æ¯”éªŒè¯
- âœ… **å®Œæ•´æµ‹è¯•**: å•å…ƒæµ‹è¯•ã€é›†æˆæµ‹è¯•ã€æ€§èƒ½æµ‹è¯•

---

## ğŸ“ ç›®å½•ç»“æ„

```
tensor_cpp/
â”œâ”€â”€ include/tensor_cpp/       # å…¬å…±å¤´æ–‡ä»¶
â”‚   â”œâ”€â”€ tensor.h              # Tensor ç±»å®šä¹‰
â”‚   â”œâ”€â”€ tensor_impl.tpp       # Tensor æ¨¡æ¿å®ç°
â”‚   â”œâ”€â”€ ops.h                 # åŸºç¡€ç®—å­ï¼ˆmatmul, add, rms_norm, ropeï¼‰
â”‚   â”œâ”€â”€ ops_avx.h             # AVX SIMD ç®—å­
â”‚   â”œâ”€â”€ ops_mpi.h             # MPI å¹¶è¡Œç®—å­
â”‚   â”œâ”€â”€ attention.h           # æ³¨æ„åŠ›æœºåˆ¶
â”‚   â”œâ”€â”€ kv_cache.h            # KV Cache å®ç°
â”‚   â”œâ”€â”€ qwen3_loader.h       # æ¨¡å‹æƒé‡åŠ è½½
â”‚   â”œâ”€â”€ qwen3_ops.h          # Qwen3 å‰å‘ä¼ æ’­
â”‚   â”œâ”€â”€ qwen3_ops_mpi.h       # MPI ç‰ˆæœ¬
â”‚   â”œâ”€â”€ qwen3_ops_avx.h      # AVX2 ä¼˜åŒ–ç‰ˆæœ¬
â”‚   â”œâ”€â”€ qwen3_tensor_parallel.h # å¼ é‡å¹¶è¡Œ
â”‚   â””â”€â”€ avx2_helpers.h        # AVX2 è¾…åŠ©å‡½æ•°åº“ â­
â”‚
â”œâ”€â”€ src/                     # å®ç°æ–‡ä»¶
â”‚   â”œâ”€â”€ tensor.cpp
â”‚   â”œâ”€â”€ ops.cpp
â”‚   â”œâ”€â”€ ops_avx.cpp
â”‚   â”œâ”€â”€ ops_mpi.cpp
â”‚   â”œâ”€â”€ attention_avx.cpp
â”‚   â”œâ”€â”€ qwen3_loader.cpp
â”‚   â”œâ”€â”€ qwen3_ops.cpp        # åŸºç¡€å®ç°
â”‚   â”œâ”€â”€ qwen3_ops_avx.cpp    # AVX2 ä¼˜åŒ–ï¼ˆæ—§ç‰ˆï¼‰
â”‚   â”œâ”€â”€ qwen3_ops_mpi_avx.cpp # MPI + AVX2
â”‚   â””â”€â”€ qwen3_tensor_parallel.cpp
â”‚
â”œâ”€â”€ tests/                   # æµ‹è¯•å¥—ä»¶ï¼ˆå·²é‡æ–°ç»„ç»‡ï¼‰
â”‚   â”œâ”€â”€ unit/                # å•å…ƒæµ‹è¯•ï¼ˆ9ä¸ªï¼‰
â”‚   â”œâ”€â”€ integration/         # é›†æˆæµ‹è¯•ï¼ˆ6ä¸ªï¼‰
â”‚   â”œâ”€â”€ benchmark/           # æ€§èƒ½æµ‹è¯•ï¼ˆ5ä¸ªï¼‰
â”‚   â”œâ”€â”€ validation/          # éªŒè¯æµ‹è¯•ï¼ˆ3ä¸ªï¼‰
â”‚   â””â”€â”€ README.md            # æµ‹è¯•æ–‡æ¡£
â”‚
â”œâ”€â”€ examples/                # ç¤ºä¾‹ä»£ç 
â”‚   â””â”€â”€ basic_usage.cpp
â”‚
â”œâ”€â”€ CMakeLists.txt
â””â”€â”€ README.md
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å‰ç½®è¦æ±‚

- GCC 9+ æˆ– Clang 10+ï¼ˆæ”¯æŒ C++17ï¼‰
- OpenMP 4.5+
- MPI 3.0+ï¼ˆå¯é€‰ï¼Œç”¨äºåˆ†å¸ƒå¼åŠŸèƒ½ï¼‰
- CPU æ”¯æŒ AVX2ï¼ˆæ¨èï¼‰

### 1. ç¼–è¯‘é¡¹ç›®

```bash
cd tensor_cpp
mkdir -p build && cd build
cmake .. -DCMAKE_BUILD_TYPE=Release
make -j$(nproc)
```

### 2. è¿è¡Œç¯å¢ƒé…ç½®

**å¦‚æœä½¿ç”¨ anacondaï¼Œéœ€è¦è®¾ç½®ç³»ç»Ÿåº“è·¯å¾„ï¼š**

```bash
export LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu:$LD_LIBRARY_PATH
```

---

## ğŸ“Š æ€§èƒ½åŸºå‡†

### Qwen3-0.6B æ¨¡å‹æ€§èƒ½ (OMP_NUM_THREADS=16)

| ç‰ˆæœ¬ | seq_len=4 | seq_len=16 | seq_len=32 | vs Baseline |
|------|-----------|------------|------------|--------------|
| **Baseline** | 4.04s | 6.81s | 15.59s | 1.0x |
| **AVX2** | 1.23s | 4.16s | 7.67s | **3.3x / 1.6x / 2.0x** |
| **MPI (2è¿›ç¨‹)** | 2.88s | 5.12s | 11.20s | 1.4x / 1.3x / 1.4x |
| **MPI+AVX2** | 1.01s | 3.45s | 6.98s | **4.0x / 2.0x / 2.2x** |

**ç¡¬ä»¶**: Intel CPU, AVX2 æ”¯æŒ

### ç»„ä»¶çº§ä¼˜åŒ–

| ç»„ä»¶ | Baseline | AVX2 | åŠ é€Ÿæ¯” |
|------|----------|------|--------|
| MLP (SwiGLU) | 172ms | 28ms | **6.1x** |
| Linear Layer | - | - | **2.9x** |
| Horizontal Sum | - | - | **~20% faster** |

---

## ğŸ§ª æµ‹è¯•

### è¿è¡Œæµ‹è¯•

```bash
cd build

# å•å…ƒæµ‹è¯•
./test_simple
./test_ops
./test_attention

# é›†æˆæµ‹è¯•
./test_qwen3                    # å®Œæ•´å‰å‘ä¼ æ’­
./test_qwen3_generate          # è‡ªå›å½’ç”Ÿæˆ
./test_qwen3_generate_with_cache # å¸¦ KV cache

# æ€§èƒ½æµ‹è¯•
OMP_NUM_THREADS=16 ./benchmark_qwen3
OMP_NUM_THREADS=16 ./benchmark_avx2_versions

# MPI æµ‹è¯•
mpirun -np 2 ./test_qwen3_mpi_simple
```

è¯¦ç»†æµ‹è¯•è¯´æ˜è¯·å‚è€ƒ [tests/README.md](tests/README.md)

---

## ğŸšï¸ ä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€å‰å‘ä¼ æ’­

```cpp
#include "tensor_cpp/qwen3_loader.h"
#include "tensor_cpp/qwen3_ops.h"

using namespace tensor_cpp;
using namespace tensor_cpp::qwen3;

// åŠ è½½æ¨¡å‹
Qwen3Weights weights = load_qwen3_weights(
    "/path/to/Qwen3-0.6B/model.safetensors"
);

// å‡†å¤‡è¾“å…¥
std::vector<long> ids = {1, 2, 3, 4};
TensorL input_ids(ids, Shape({1, 4}));

// å‰å‘ä¼ æ’­
Tensor output = qwen3::qwen3_forward(
    input_ids,
    weights.embed_tokens,
    weights.layers,
    weights.norm_weight,
    weights.num_layers,
    weights.num_attention_heads,
    weights.num_key_value_heads,
    weights.head_dim,
    1e-6f  // rms_norm_eps
);
```

### ä½¿ç”¨ AVX2 ä¼˜åŒ–ç‰ˆæœ¬

```cpp
#include "tensor_cpp/qwen3_ops_avx.h"

using namespace tensor_cpp::qwen3::avx2;

Tensor output = avx2::qwen3_forward_avx(
    input_ids,
    weights.embed_tokens,
    weights.layers,
    weights.norm_weight,
    weights.num_layers,
    weights.num_attention_heads,
    weights.num_key_value_heads,
    weights.head_dim,
    1e-6f
);
```

### ä½¿ç”¨ KV Cache åŠ é€Ÿç”Ÿæˆ

```cpp
#include "tensor_cpp/qwen3_ops.h"

TensorKVCache kv_cache(
    weights.num_layers,
    weights.num_key_value_heads,
    128,  // max_seq_len
    1024  // hidden_size
);

// Prefill é˜¶æ®µ
Tensor output = qwen3_forward_with_cache(
    input_ids,
    weights,
    kv_cache
);

// Decode é˜¶æ®µï¼ˆè¿­ä»£ç”Ÿæˆï¼‰
for (int i = 0; i < 10; ++i) {
    Tensor next_token = qwen3_forward_with_cache(
        last_token,
        weights,
        kv_cache
    );
}
```

---

## ğŸ”§ å®ç°ç‰ˆæœ¬å¯¹æ¯”

| å®ç°ç‰ˆæœ¬ | å‘½åç©ºé—´ | ç‰¹æ€§ | æ€§èƒ½ | æ¨èåœºæ™¯ |
|---------|---------|------|------|---------|
| **åŸºç¡€ç‰ˆ** | `qwen3::` | æ ‡å‡† OpenMP | åŸºå‡† | åŠŸèƒ½éªŒè¯ã€è°ƒè¯• |
| **AVX2** | `qwen3::avx2::` | MLP ä¼˜åŒ– | 1.6-3.3x | å•æœºæ¨ç† |
| **AVX2 V2** | `qwen3::avx2_v2::` | å…¨é¢ä¼˜åŒ– | æœ€é«˜ | å•æœºæ¨ç†ï¼ˆæ¨èï¼‰ |
| **MPI** | `qwen3::mpi::` | æ•°æ®å¹¶è¡Œ | 1.3-1.4x | å¤šèŠ‚ç‚¹ |
| **MPI+AVX2** | `qwen3::mpi_avx::` | æ··åˆå¹¶è¡Œ | æœ€é«˜ | å¤šèŠ‚ç‚¹ï¼ˆæ¨èï¼‰ |
| **å¼ é‡å¹¶è¡Œ** | `qwen3::tensor_parallel::` | æ¨¡å‹åˆ‡åˆ† | - | å¤§æ¨¡å‹ |

### æ¨èä½¿ç”¨

**å•æœºæ¨ç†ï¼š**
```cpp
using namespace tensor_cpp::qwen3::avx2;  // æˆ– avx2_v2ï¼ˆæœ€ä¼˜ï¼‰
```

**åˆ†å¸ƒå¼æ¨ç†ï¼š**
```cpp
using namespace tensor_cpp::qwen3::mpi_avx;
```

---

## ğŸ“ˆ ä¼˜åŒ–æŠ€æœ¯

### 1. AVX2 SIMD ä¼˜åŒ–

**æ°´å¹³æ±‚å’Œä¼˜åŒ–**ï¼ˆ`avx2_helpers.h`ï¼‰:
```cpp
// æ—§æ–¹æ³•ï¼ˆä½¿ç”¨ haddï¼‰
__m256 sum = _mm256_hadd_ps(v, v);
sum = _mm256_hadd_ps(sum, sum);

// æ–°æ–¹æ³•ï¼ˆä½¿ç”¨ shuffleï¼Œå¿«20%ï¼‰
float result = avx2_helpers::hsum_avx2(v);
```

**MLP ä¼˜åŒ–**:
- Gate/Up æŠ•å½±ï¼šAVX2 å‘é‡åŒ–
- SwiGLU æ¿€æ´»ï¼šå¿«é€Ÿ sigmoid è¿‘ä¼¼
- Down æŠ•å½±ï¼šAVX2 å‘é‡åŒ–
- **æ€»ä½“åŠ é€Ÿ**: 6.1x

### 2. KV Cache ä¼˜åŒ–

- **Prefill é˜¶æ®µ**: ä¸€æ¬¡æ€§å¤„ç†æ‰€æœ‰ token
- **Decode é˜¶æ®µ**: å¤ç”¨ç¼“å­˜çš„ K/Vï¼Œåªè®¡ç®—æ–° token
- **æ€§èƒ½æå‡**: 1.74xï¼ˆdecode é˜¶æ®µï¼‰

### 3. é¢„æå– QKV æŠ•å½±

**ä¼˜åŒ–å‰**ï¼ˆæ¯æ¬¡å‰å‘ä¼ æ’­ï¼‰:
```cpp
// æ¯å±‚éƒ½éœ€è¦æå– Q, K, V
for (int layer = 0; layer < 28; ++layer) {
    // ä» qkv_projs æå– Q, K, V
    // 28 å±‚ Ã— 3 æ¬¡ = 84 æ¬¡çŸ©é˜µå¤åˆ¶
}
```

**ä¼˜åŒ–å**ï¼ˆæ¨¡å‹åŠ è½½æ—¶ï¼‰:
```cpp
// é¢„æå–å¹¶ä¿å­˜
layer.q_proj = extract_q_proj(qkv_projs);
layer.k_proj = extract_k_proj(qkv_projs);
layer.v_proj = extract_v_proj(qkv_projs);
// èŠ‚çœï¼š~336MB å†…å­˜å¤åˆ¶ + 84 æ¬¡çŸ©é˜µåˆ›å»º
```

### 4. MPI æ•°æ®å¹¶è¡Œ

- æ¯ä¸ªè¿›ç¨‹å¤„ç†éƒ¨åˆ†æ•°æ®
- AllReduce èšåˆæ¢¯åº¦
- æ”¯æŒ 2-16 è¿›ç¨‹

---

## ğŸ› ï¸ å¼€å‘æŒ‡å—

### æ·»åŠ æ–°çš„ä¼˜åŒ–å®ç°

1. **åˆ›å»ºæ–°æ–‡ä»¶**: `src/qwen3_ops_<optimization>.cpp`
2. **å‘½åç©ºé—´**: `namespace tensor_cpp::qwen3::<optimization>`
3. **å¯¼å‡ºå‡½æ•°**:
   ```cpp
   Tensor qwen3_forward_<optimization>(...);
   ```
4. **æ›´æ–° CMakeLists.txt**: æ·»åŠ ç¼–è¯‘ç›®æ ‡å’Œæ ‡å¿—
5. **æ·»åŠ æµ‹è¯•**: åœ¨ `tests/integration/` æˆ– `tests/benchmark/`

### ä½¿ç”¨ AVX2 è¾…åŠ©å‡½æ•°

```cpp
#include "tensor_cpp/avx2_helpers.h"

// ä½¿ç”¨ä¼˜åŒ–çš„æ°´å¹³æ±‚å’Œ
__m256 v = _mm256_fmadd_ps(a, b, c);
float sum = avx2_helpers::hsum_avx2(v);

// ä½¿ç”¨å¿«é€Ÿ sigmoid
__m256 x = _mm256_loadu_ps(input);
__m256 sigmoid = avx2_helpers::sigmoid_fast_avx2(x);
```

---

## ğŸ“š æ¶æ„è¯´æ˜

### Qwen3 æ¨¡å‹æ¶æ„

```
Input Tokens
    â†“
Token Embedding
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Qwen3 Decoder Layer (Ã—28)            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Input RMSNorm + Residual         â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â”‚ Self-Attention (GQA)             â”‚ â”‚
â”‚  â”‚  - Q Projection                  â”‚ â”‚
â”‚  â”‚  - K Projection                  â”‚ â”‚
â”‚  â”‚  - V Projection                  â”‚ â”‚
â”‚  â”‚  - QK Norm                      â”‚ â”‚
â”‚  â”‚  - RoPE                         â”‚ â”‚
â”‚  â”‚  - Scaled Dot-Product Attention  â”‚ â”‚
â”‚  â”‚  - O Projection                  â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â”‚ Residual Connection              â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â”‚ Post-Attention RMSNorm + Residualâ”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â”‚ MLP (SwiGLU)                     â”‚ â”‚
â”‚  â”‚  - Gate Projection               â”‚ â”‚
â”‚  â”‚  - Up Projection                 â”‚ â”‚
â”‚  â”‚  - SwiGLU Activation             â”‚ â”‚
â”‚  â”‚  - Down Projection               â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Final RMSNorm
    â†“
Output Logits
```

### æ³¨æ„åŠ›æœºåˆ¶

- **åˆ†ç»„æŸ¥è¯¢æ³¨æ„åŠ› (GQA)**: 8ä¸ª KV headsï¼Œ16ä¸ª query heads
- **Head dimension**: 128
- **RoPE**: æ—‹è½¬ä½ç½®ç¼–ç ï¼ˆ128ç»´ï¼‰

---

## ğŸ” å·²çŸ¥é—®é¢˜ä¸é™åˆ¶

### å½“å‰é™åˆ¶

1. **ä»…æ”¯æŒ CPU æ¨ç†**: æ—  GPU å®ç°
2. **å›ºå®š batch size = 1**: æ¨ç†ä¼˜åŒ–
3. **max_seq_len = 128**: KV cache é™åˆ¶

### TODO

- [ ] æ”¯æŒå˜é•¿åºåˆ—
- [ ] æ·»åŠ é‡åŒ–æ”¯æŒ (INT8/FP16)
- [ ] å®ç°æ‰¹å¤„ç†æ¨ç†
- [ ] æ·»åŠ æ›´å¤šæ¨¡å‹ï¼ˆQwen2, Qwen1.5ï¼‰

---

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ª MIT è®¸å¯è¯ã€‚

---

## ğŸ™ è‡´è°¢

- Qwen æ¨¡å‹ï¼šé˜¿é‡Œå·´å·´è¾¾æ‘©é™¢
- Safetensorsï¼šHuggingFace
- AVX2 ä¼˜åŒ–å‚è€ƒï¼šè‹±ç‰¹å°” intrinsics æŒ‡å—

---

## ğŸ“§ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œæ¬¢è¿æäº¤ Issue æˆ– Pull Requestã€‚

**æœ€åæ›´æ–°**: 2026-01-12
