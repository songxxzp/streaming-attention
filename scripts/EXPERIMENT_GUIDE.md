# 并行计算课程实验指南

## 一键运行

在服务器上执行：

```bash
cd ~/projects/final/scripts
./run_all_experiments.sh
```

脚本会自动完成所有实验并保存结果到 `results/experiment_<timestamp>/`

---

## 实验设计

### 实验1: Attention算子性能扩展性测试

**目的**: 对比串行、OpenMP、MPI+OpenMP三种并行模式的性能

#### 测试配置
- 隐藏维度: 128
- 块大小: 64
- 迭代次数: 10

#### 测试变量

**1.1 串行Baseline**
- 序列长度: 512, 1024, 2048, 4096, 8192
- 目的: 获取性能基准

**1.2 OpenMP并行扩展性**
- 序列长度: 2048 (固定)
- 线程数: 1, 2, 4, 8, 16, 26, 52, 104, 208, 416
- 目的: 测试共享内存并行的扩展性

**1.3 MPI+OpenMP混合并行**
- 序列长度: 2048 (固定)
- MPI进程数: 1, 2, 4, 8, 16
- 每进程OpenMP线程数: 26 (固定)
- 总核数: 26, 52, 104, 208, 416
- 目的: 测试分布式内存+共享内存混合并行

#### 测试指标
- **执行时间** (ms): 完成一次attention计算的时间
- **吞吐量** (tokens/sec): 每秒处理的token数
- **加速比**: 串行时间 / 并行时间
- **并行效率**: 加速比 / 处理器数

#### 课程报告要点

1. **加速比曲线**: 绘制加速比vs处理器数曲线
2. **并行效率**: 分析效率随处理器数增加的变化趋势
3. **最优处理器数**: 找出性价比最高的配置
4. **OpenMP vs MPI+OpenMP**: 对比两种并行方式的优劣

---

### 实验2: Qwen3模型吞吐量测试

**目的**: 测试Prefill和Decode两个阶段的性能扩展性

#### 2.1 Prefill阶段测试

**测试配置**
- Prompt长度: 512, 1024, 2048, 4096
- 线程数: 1, 4, 16, 52, 104, 208, 416
- 迭代次数: 3

**为什么测试Prefill?**
- Prefill是计算密集型阶段
- 可以充分利用多核并行
- 测试理论加速比上限

#### 2.2 Decode阶段测试

**测试配置**
- 生成长度: 512, 1024
- 线程数: 1, 4, 16, 52, 104, 208, 416
- 迭代次数: 1
- 使用KV Cache避免重复计算

**为什么测试Decode?**
- Decode是内存带宽密集型阶段
- 每步只处理一个token，并行度受限
- 更贴近实际应用场景

#### 测试指标
- **总时间** (ms): 完成指定长度生成的时间
- **吞吐量** (tokens/sec): 每秒生成的token数
- **加速比**: 相对于串行的性能提升
- **并行效率**: 资源利用率

#### 课程报告要点

1. **Prefill vs Decode**: 两个阶段的性能特征对比
2. **扩展性分析**: 不同prompt/生成长度下的扩展性
3. **实际应用**: 推断实际场景中的最优配置

---

## 硬件配置

- **节点数**: 8
- **每节点CPU数**: 2
- **每CPU核数**: 26
- **总核数**: 8 × 2 × 26 = 416核

---

## 测试数据说明

### 输出文件结构

```
results/experiment_<timestamp>/
├── experiment_design.txt      # 实验设计说明
├── SUMMARY.md                  # 总结报告（Markdown格式）
├── attention_serial.txt        # 串行baseline数据
├── attention_omp.txt          # OpenMP并行数据
├── attention_mpi.txt          # MPI+OpenMP混合数据
├── qwen3_prefill.txt         # Prefill阶段数据
├── qwen3_decode.txt          # Decode阶段数据
├── attention_serial_compile.log   # 编译日志
├── attention_omp_compile.log      # 编译日志
└── attention_mpi_compile.log      # 编译日志
```

### 数据格式示例

#### Attention串行测试
```
序列长度 | 时间(ms) | 吞吐量(tokens/s)
---------|---------|------------------
    512   |   12.34 |          41491.02
   1024   |   45.67 |          22420.19
```

#### OpenMP并行测试
```
线程数 | 时间(ms) | 吞吐量(tokens/s) | 加速比 | 效率
------|---------|------------------|--------|------
   1   |  180.23 |           11317.47 |   1.00 | 1.000
   2   |   92.45 |           22054.89 |   1.95 | 0.975
   4   |   48.12 |           42427.01 |   3.74 | 0.935
  16   |   15.67 |          130244.36 |  11.50 | 0.719
  52   |    8.34 |          244604.32 |  21.61 | 0.416
```

#### Qwen3 Prefill测试
```
Prompt长度 | 线程数 | 时间(ms) | 吞吐量(tokens/s) | 加速比 | 效率
----------|-------|---------|-----------------|--------|------
     512  |     1 |  234.56 |          2182.73 |   1.00 | 1.000
     512  |    16 |   18.23 |         28085.24 |  12.86 | 0.804
     512  |    52 |    8.45 |         60591.72 |  27.75 | 0.534
```

---

## 课程报告撰写指南

### 1. 问题与建模 (10分)

#### 1.1 问题背景
- 大语言模型推理中的计算瓶颈
- Attention机制的O(n²)复杂度
- Prefill和Decode两个阶段的不同特征

#### 1.2 物理建模
- 多核CPU架构 (8节点×2CPU×26核)
- NUMA架构
- 内存层次结构

#### 1.3 数学建模
- Standard Attention复杂度: O(n²×d)
- Streaming Attention复杂度: O(n²×d) 但cache-friendly
- 计算公式:
  - 加速比 = T₁ / Tₚ
  - 并行效率 = 加速比 / p

### 2. 算法设计 (20分)

#### 2.1 串行算法
- 描述标准Attention计算流程
- 时间复杂度分析

#### 2.2 并行算法

**OpenMP并行**:
- 任务划分: 按attention头、序列位置分块
- 通信策略: 共享内存，无需显式通信
- 负载均衡: static schedule

**MPI+OpenMP混合并行**:
- 任务划分: MPI进程间数据分布 + 进程内OpenMP并行
- 通信策略:
  - MPI_Bcast: 广播Query向量
  - MPI_Gather: 收集部分结果
  - 树规约: 合并Online Softmax状态
- 负载均衡: 均匀划分KV cache

#### 2.3 正确性证明
- Online Softmax数学等价性
- 树规约的正确性

### 3. 程序实现 (20分)

#### 3.1 硬件环境
- CPU: Intel Xeon (26核×2×8节点)
- 编译器: GCC with OpenMP + OpenMPI
- 优化选项: -O3 -march=native

#### 3.2 关键代码
- `attention/streaming_omp.cpp`: OpenMP并行实现
- `attention/streaming_mpi.cpp`: MPI+OpenMP混合实现
- `tensor_cpp/src/ops.cpp`: Self-attention算子
- `tensor_cpp/src/qwen3_ops.cpp`: Qwen3模型实现

#### 3.3 优化技术
- SIMD向量化 (编译器自动)
- Cache-friendly分块 (Streaming Attention)
- NUMA-aware内存分配

### 4. 性能分析 (30分)

#### 4.1 加速比曲线
- 使用实验数据绘制曲线
- 对比理论加速比 vs 实际加速比
- 分析偏差原因

#### 4.2 并行效率
- 计算各配置下的并行效率
- 分析效率下降原因:
  - 通信开销
  - 负载不均衡
  - 内存带宽瓶颈
  - Amdahl定律限制

#### 4.3 可扩展性分析

**强扩展性** (固定问题规模):
- 绘制性能vs处理器数曲线
- 分析可扩展性上限

**弱扩展性** (问题规模随处理器增长):
- 推测弱扩展性表现

#### 4.4 最优处理器数
- 找出性价比最高的配置
- 考虑性能/功耗比

### 5. 总结展望 (10分)

#### 5.1 结论
- OpenMP适合单节点多核
- MPI+OpenMP适合多节点扩展
- Prefill阶段扩展性好
- Decode阶段受内存带宽限制

#### 5.2 不足
- 未实现GPU加速
- 未优化内存访问模式
- 未测试实际推理场景

#### 5.3 未来工作
- 实现Flash Attention
- 添加INT8量化
- 支持Batch并行
- 实现Pipeline并行

---

## 常见问题

### Q1: 脚本运行失败？
A: 检查以下项：
1. 模型文件是否存在
2. 是否已编译项目: `./build_on_server.sh`
3. MPI是否可用: `which mpirun`

### Q2: 某些测试耗时太长？
A: 可以修改脚本中的配置：
- 减少序列长度
- 减少迭代次数
- 减少测试的线程数配置

### Q3: 如何只运行部分实验？
A: 注释掉脚本中不需要的部分

### Q4: 如何自定义测试配置？
A: 编辑 `run_all_experiments.sh` 中的以下变量：
```bash
SEQ_LEN_LIST=(512 1024 2048 4096)  # 序列长度
THREADS_LIST=(1 2 4 8 16 26 52)     # 线程数
ITERS=10                             # 迭代次数
```

---

## 联系与支持

如有问题，请查看：
- 项目README: `tensor_cpp/README.md`
- 脚本文档: `scripts/README.md`
- 实验设计: `results/experiment_*/experiment_design.txt`

---

**最后更新**: 2026年1月11日
**适用课程**: 并行计算
