# Streaming Block Attention & Qwen3 Tensor Library

é¢å‘å¤š NUMAã€å¤šèŠ‚ç‚¹ CPU é›†ç¾¤çš„ Streaming Block Attention å¹¶è¡ŒåŒ–å®ç°ä¸ Qwen3 LLM æ¨ç†åº“ã€‚

## ğŸ“„ å®Œæ•´è®ºæ–‡

**æœ¬é¡¹ç›®çš„ç ”ç©¶æŠ¥å‘Šå·²æ•´ç†ä¸ºå­¦æœ¯è®ºæ–‡ï¼Œè¯·æŸ¥çœ‹ï¼š[Paper.pdf](Paper.pdf)**

è¯¥è®ºæ–‡åŒ…å«å®Œæ•´çš„ï¼š
- ç ”ç©¶èƒŒæ™¯ä¸åŠ¨æœº
- æ–¹æ³•è®¾è®¡ä¸å®ç°
- å®éªŒç»“æœä¸åˆ†æï¼ˆä¸²è¡Œã€OpenMPã€MPI å¹¶è¡Œæ€§èƒ½å¯¹æ¯”ï¼‰
- åºåˆ—å¹¶è¡Œ vs å¤´ç»´å¹¶è¡Œçš„ç³»ç»Ÿæ€§ç ”ç©¶
- Streaming Attention ç®—æ³•ä¼˜åŒ–æ•ˆæœ
- åœ¨ Qwen3-0.6B æ¨¡å‹ä¸Šçš„ç«¯åˆ°ç«¯æ€§èƒ½è¯„ä¼°

**ä¸»è¦ç»“è®º**ï¼š
- Streaming Attention ç›¸æ¯”ä¼ ç»Ÿæ–¹æ³•æå‡ 2.61Ã— - 6.41Ã—
- 8 èŠ‚ç‚¹è¾¾åˆ° 14.29 tok/s ååé‡
- åºåˆ—å¹¶è¡Œ + online softmax æ˜¯æœ€ä¼˜ç»„åˆ
- ç®—æ³•ä¼˜åŒ–ä¼˜äºç®—å­ä¼˜åŒ–ï¼ˆ5.8Ã— æ”¶ç›Šæ¯”ï¼‰

## ğŸ“ é¡¹ç›®ç»“æ„

```
final/
â”œâ”€â”€ README.md                      # é¡¹ç›®ä¸»æ–‡æ¡£
â”‚
â”œâ”€â”€ docs/                          # ğŸ“š é¡¹ç›®æ–‡æ¡£
â”‚   â”œâ”€â”€ ATTENTION_REPORT.md        # Attention ç®—å­å®éªŒæŠ¥å‘Š
â”‚   â”œâ”€â”€ MPI_IMPLEMENTATION_COMPARISON.md  # MPI å®ç°å¯¹æ¯”åˆ†æ
â”‚   â””â”€â”€ QWEN3_MPI_GUIDE.md         # Qwen3 MPI ä½¿ç”¨æŒ‡å—
â”‚
â”œâ”€â”€ attention/                     # ğŸ¯ Streaming Block Attention å®ç°
â”‚   â”œâ”€â”€ src/                       # æºä»£ç 
â”‚   â”‚   â”œâ”€â”€ attention.h            # å…¬å…±å¤´æ–‡ä»¶
â”‚   â”‚   â”œâ”€â”€ naive_serial.cpp       # Naive ä¸²è¡Œå®ç°
â”‚   â”‚   â”œâ”€â”€ streaming_serial.cpp   # Streaming ä¸²è¡Œå®ç°
â”‚   â”‚   â”œâ”€â”€ streaming_omp.cpp      # OpenMP å¹¶è¡Œå®ç°
â”‚   â”‚   â””â”€â”€ streaming_mpi.cpp      # MPI+OpenMP æ··åˆå¹¶è¡Œå®ç°
â”‚   â”œâ”€â”€ tests/                     # æµ‹è¯•ä»£ç 
â”‚   â””â”€â”€ scripts/                   # compare_attention_full.py æ€§èƒ½å¯¹æ¯”è„šæœ¬
â”‚
â”œâ”€â”€ tensor_cpp/                    # ğŸ§  Qwen3 C++ Tensor åº“
â”‚   â”œâ”€â”€ README.md                  # è¯¦ç»†æ–‡æ¡£
â”‚   â”œâ”€â”€ include/tensor_cpp/        # å¤´æ–‡ä»¶
â”‚   â”‚   â”œâ”€â”€ tensor.h               # Tensor ç±»å®šä¹‰
â”‚   â”‚   â”œâ”€â”€ ops.h                  # åŸºç¡€ç®—å­
â”‚   â”‚   â”œâ”€â”€ ops_avx.h              # AVX SIMD ç®—å­
â”‚   â”‚   â”œâ”€â”€ ops_mpi.h              # MPI å¹¶è¡Œç®—å­
â”‚   â”‚   â”œâ”€â”€ qwen3_ops.h            # Qwen3 å‰å‘ä¼ æ’­
â”‚   â”‚   â”œâ”€â”€ qwen3_ops_avx.h        # AVX2 ä¼˜åŒ–ç‰ˆæœ¬
â”‚   â”‚   â”œâ”€â”€ qwen3_ops_mpi.h        # MPI ç‰ˆæœ¬
â”‚   â”‚   â””â”€â”€ kv_cache.h             # KV Cache å®ç°
â”‚   â”œâ”€â”€ src/                       # æºæ–‡ä»¶å®ç°
â”‚   â”œâ”€â”€ tests/benchmark/           # æ€§èƒ½æµ‹è¯•
â”‚   â”œâ”€â”€ scripts/                   # å®éªŒè„šæœ¬
â”‚   â”‚   â”œâ”€â”€ exp1_serial_baseline.sh
â”‚   â”‚   â”œâ”€â”€ exp2_single_node_n_threads.sh
â”‚   â”‚   â”œâ”€â”€ exp3_mpi_parallel.sh
â”‚   â”‚   â”œâ”€â”€ exp4_thread_scaling.sh
â”‚   â”‚   â”œâ”€â”€ exp5_node_scaling.sh
â”‚   â”‚   â”œâ”€â”€ exp6_block_size_tuning.sh
â”‚   â”‚   â””â”€â”€ README_EXPERIMENTS.md  # å®éªŒè„šæœ¬å®Œæ•´æ–‡æ¡£
â”‚   â””â”€â”€ results/                   # å®éªŒç»“æœ
â”‚
â”œâ”€â”€ experiments/                   # ğŸ“Š å®éªŒæ•°æ®å’Œå¯è§†åŒ–
â”‚   â”œâ”€â”€ data/                      # åŸå§‹ CSV æ•°æ®
â”‚   â””â”€â”€ figures/                   # ç»˜å›¾è„šæœ¬å’Œå›¾è¡¨
â”‚
â”œâ”€â”€ scripts/                       # ğŸ”§ é€šç”¨å·¥å…·è„šæœ¬
â”œâ”€â”€ utils/                         # å·¥å…·åº“
â””â”€â”€ build/                         # ç¼–è¯‘è¾“å‡º
```

## ğŸ“– æ–‡æ¡£å¯¼èˆª

- **[Attention ç®—å­å®éªŒæŠ¥å‘Š](docs/ATTENTION_REPORT.md)** - Streaming Attention æ€§èƒ½åˆ†æ
- **[MPI å®ç°å¯¹æ¯”](docs/MPI_IMPLEMENTATION_COMPARISON.md)** - MPI vs MPI+AVX2 è¯¦ç»†å¯¹æ¯”
- **[Qwen3 MPI ä½¿ç”¨æŒ‡å—](docs/QWEN3_MPI_GUIDE.md)** - MPI å¹¶è¡Œé…ç½®å’Œè¿è¡Œ
- **[Tensor_cpp README](tensor_cpp/README.md)** - C++ åº“è¯¦ç»†æ–‡æ¡£
- **[å®éªŒè„šæœ¬æŒ‡å—](tensor_cpp/scripts/README_EXPERIMENTS.md)** - Qwen3 æ€§èƒ½å®éªŒè„šæœ¬å®Œæ•´è¯´æ˜

## ğŸš€ å¿«é€Ÿå¼€å§‹

### Attention ç®—å­æµ‹è¯•

```bash
# ç¼–è¯‘å¹¶æµ‹è¯•
cd attention
make test_mpi
mpirun -np 4 ./test_mpi --T 8192 --d 128 --block 64

# æ€§èƒ½å¯¹æ¯”åˆ†æ
python scripts/compare_attention_full.py
```

### Qwen3 æ¨ç†

```bash
# ç¼–è¯‘
cd tensor_cpp/build
cmake ..
make -j

# Prefill é˜¶æ®µåŸºå‡†æµ‹è¯• (å¤„ç†é•¿æç¤ºè¯)
./benchmark_qwen3 --model /path/to/qwen3-0.6B/model.safetensors \
  --method mpi+avx2 \
  --parallel-strategy sequence \
  --attention-algo online_softmax \
  --prompt-len 128 \
  --iters 3

# Decode é˜¶æ®µæ€§èƒ½éªŒè¯ (è‡ªå›å½’ç”Ÿæˆ)
mpirun -np 2 ./benchmark_qwen3 \
  --model /path/to/qwen3-0.6B/model.safetensors \
  --method mpi+avx2 \
  --parallel-strategy sequence \
  --attention-algo online_softmax \
  --prompt-len 128 \
  --generate 100 \
  --threads 8

# æ­£ç¡®æ€§éªŒè¯ (ä¸ PyTorch è¾“å‡ºå¯¹æ¯”)
mpirun -np 2 ./benchmark_qwen3 \
  --model /path/to/qwen3-0.6B/model.safetensors \
  --method mpi+avx2 \
  --parallel-strategy sequence \
  --attention-algo online_softmax \
  --prompt-len 32 \
  --verify
```

### Attention ç®—å­æ€§èƒ½å¯¹æ¯”

```bash
# æ–¹å¼1: åœ¨ attention/ ç›®å½•ç¼–è¯‘å’Œè¿è¡Œ
cd attention
make                    # ç¼–è¯‘ä¸²è¡Œå’Œ OpenMP ç‰ˆæœ¬
make mpi                # ç¼–è¯‘ MPI ç‰ˆæœ¬ (å¯é€‰)

# è¿è¡Œå®Œæ•´æ€§èƒ½å¯¹æ¯”æµ‹è¯•
python scripts/compare_attention_full.py \
  --seq-lens 1024 8192 \
  --hidden-dim 128 \
  --threads 1 2 4 8 \
  --block-sizes 64 128

# æ–¹å¼2: ä»é¡¹ç›®æ ¹ç›®å½•è¿è¡Œ
cd /path/to/final
python attention/scripts/compare_attention_full.py --help

# å¿«é€Ÿæµ‹è¯•
python attention/scripts/compare_attention_full.py \
  --seqlen 512 --dim 64 --threads 1 --repeat 2
```

**Makefile ç›®æ ‡**:
- `make` æˆ– `make all` - ç¼–è¯‘ä¸²è¡Œå’Œ OpenMP ç‰ˆæœ¬
- `make serial` - ä»…ç¼–è¯‘ä¸²è¡Œç‰ˆæœ¬
- `make openmp` - ä»…ç¼–è¯‘ OpenMP ç‰ˆæœ¬
- `make mpi` - ç¼–è¯‘ MPI ç‰ˆæœ¬ (éœ€è¦ mpicxx)
- `make clean` - æ¸…ç†ç¼–è¯‘äº§ç‰©
- `make help` - æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯

**æµ‹è¯•é¡¹ç›®**:
- PyTorch `F.scaled_dot_product_attention` (baseline)
- C++ Naive Attention (ä¸²è¡Œ / OpenMP / MPI)
- C++ Streaming Attention (ä¸²è¡Œ / OpenMP / MPI)

**è¾“å‡º**:
- å„å®ç°çš„å»¶è¿Ÿå’Œååé‡å¯¹æ¯”
- åŠ é€Ÿæ¯”åˆ†æ
- é€šä¿¡å¼€é”€ç»Ÿè®¡ (MPIç‰ˆæœ¬)

**è·¯å¾„è‡ªåŠ¨æ£€æµ‹**: `compare_attention_full.py` æ”¯æŒä»ä»»æ„ä½ç½®è¿è¡Œï¼š
- é¡¹ç›®æ ¹ç›®å½• â†’ è‡ªåŠ¨ä½¿ç”¨ `./attention/` è·¯å¾„
- `attention/` ç›®å½• â†’ è‡ªåŠ¨ä½¿ç”¨å½“å‰ç›®å½•
- `attention/scripts/` ç›®å½• â†’ è‡ªåŠ¨ä½¿ç”¨ `..` è·¯å¾„

**è¿è¡Œå•ä¸ªæµ‹è¯•**:
```bash
cd attention
./test_naive 1024 128 64              # Naive ä¸²è¡Œ
OMP_NUM_THREADS=4 ./test_naive_omp 1024 128 64  # Naive OpenMP
mpirun -np 2 ./test_naive_mpi 1024 128 4       # Naive MPI
```

### Qwen3 æ€§èƒ½å®éªŒè„šæœ¬

```bash
cd tensor_cpp

# è¿è¡Œå•ä¸ªå®éªŒ
./scripts/exp1_serial_baseline.sh        # ä¸²è¡Œbaseline
./scripts/exp2_single_node_n_threads.sh  # å•æœºå¤šçº¿ç¨‹
./scripts/exp3_mpi_parallel.sh           # MPIå¹¶è¡Œ (é›†ç¾¤)

# è¿è¡Œæ‰€æœ‰å®éªŒ
./scripts/run_all_experiments.sh
```

**å®éªŒç³»åˆ—**:
1. **exp1_serial_baseline**: ä¸²è¡Œ baseline (baseline vs avx2)
2. **exp2_single_node_n_threads**: å•æœºå¤šçº¿ç¨‹æ‰©å±•æ€§
3. **exp3_mpi_parallel**: å¤šèŠ‚ç‚¹ MPI å¹¶è¡Œ (1/2/4/8 nodes)
4. **exp4_thread_scaling**: çº¿ç¨‹æ‰©å±•æ€§åˆ†æ
5. **exp5_node_scaling**: èŠ‚ç‚¹æ‰©å±•æ€§åˆ†æ
6. **exp6_block_size_tuning**: Block size è°ƒä¼˜

è¯¦ç»†è¯´æ˜è§ [å®éªŒè„šæœ¬å®Œæ•´æ–‡æ¡£](tensor_cpp/scripts/README_EXPERIMENTS.md)

## ğŸ“Š æ€§èƒ½äº®ç‚¹

### Attention ç®—å­

- âœ… OpenMP å¹¶è¡Œ: 4.5x åŠ é€Ÿæ¯” (16 çº¿ç¨‹)
- âœ… MPI å¼ºæ‰©å±•: æ”¯æŒå¤šèŠ‚ç‚¹åˆ†å¸ƒå¼è®¡ç®—
- âœ… å†…å­˜ä¼˜åŒ–: Online Softmax é™ä½å†…å­˜å ç”¨

### Qwen3 æ¨ç†

- âœ… **MPI+AVX2 (8èŠ‚ç‚¹)**: 70+ tok/s (åºåˆ—å¹¶è¡Œï¼Œé•¿åº¦128)
- âœ… **çœŸåºåˆ—å¹¶è¡Œ**: æ¶ˆé™¤å†—ä½™è®¡ç®—
- âœ… **AVX2 ä¼˜åŒ–**: 27% æ€§èƒ½æå‡
- âœ… **æ­£ç¡®æ€§éªŒè¯**: ä¸ PyTorch è¾“å‡ºä¸€è‡´

è¯¦ç»†æ€§èƒ½æ•°æ®è§ [å®éªŒç»“æœ](experiments/data/)ã€‚

## ğŸ”§ å¼€å‘ç¯å¢ƒ

- **ç¼–è¯‘å™¨**: GCC 9+ (æ”¯æŒ C++17)
- **MPI**: OpenMPI 4+
- **SIMD**: AVX2 æ”¯æŒ
- **ç³»ç»Ÿ**: Linux x86_64

## ğŸ“œ è®¸å¯è¯

æœ¬é¡¹ç›®ç”¨äºå­¦æœ¯ç ”ç©¶å’Œæ•™å­¦ç›®çš„ã€‚
