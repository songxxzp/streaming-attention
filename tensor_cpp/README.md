# Tensor C++ Library - Qwen3 Implementation

é«˜æ€§èƒ½çš„ C++ Tensor åº“ï¼ŒåŒ…å« Qwen3-0.6B æ¨¡å‹çš„å®Œæ•´å®ç°ã€‚æ”¯æŒ OpenMP å¹¶è¡Œå’Œ KV Cache ä¼˜åŒ–ã€‚

## ç‰¹æ€§

- âœ… **Qwen3-0.6B æ¨¡å‹å®Œæ•´å®ç°**: 28å±‚Transformeræ¶æ„
- âœ… **KV Cache æ”¯æŒ**: å¤§å¹…æå‡decodeé˜¶æ®µæ€§èƒ½
- âœ… **OpenMP å¹¶è¡Œ**: å¤šçº¿ç¨‹åŠ é€Ÿ
- âœ… **Safetensors æ ¼å¼**: æ”¯æŒHuggingFaceæ¨¡å‹æƒé‡

## ç›®å½•ç»“æ„

```
tensor_cpp/
â”œâ”€â”€ include/tensor_cpp/       # å¤´æ–‡ä»¶
â”‚   â”œâ”€â”€ tensor.h             # Tensorç±»å®šä¹‰
â”‚   â”œâ”€â”€ tensor_impl.tpp      # Tensorå®ç°
â”‚   â”œâ”€â”€ ops.h                # ç®—å­å®ç°ï¼ˆlinear, rms_norm, ropeç­‰ï¼‰
â”‚   â”œâ”€â”€ qwen3_loader.h       # Qwen3æ¨¡å‹åŠ è½½å™¨
â”‚   â”œâ”€â”€ qwen3_ops.h          # Qwen3å‰å‘ä¼ æ’­
â”‚   â””â”€â”€ kv_cache.h           # KV Cacheå®ç°
â”‚
â”œâ”€â”€ src/                     # æºæ–‡ä»¶
â”‚   â”œâ”€â”€ tensor.cpp
â”‚   â”œâ”€â”€ ops.cpp
â”‚   â”œâ”€â”€ qwen3_loader.cpp
â”‚   â””â”€â”€ qwen3_ops.cpp
â”‚
â”œâ”€â”€ tests/                   # æµ‹è¯•ç¨‹åºï¼ˆ30ä¸ªæ–‡ä»¶ï¼‰
â”‚   â”œâ”€â”€ test_qwen3_logits.cpp           # Forward passç¤ºä¾‹ â­
â”‚   â”œâ”€â”€ test_qwen3_generate.cpp         # è‡ªå›å½’ç”Ÿæˆç¤ºä¾‹ â­
â”‚   â””â”€â”€ test_qwen3_generate_with_cache.cpp # KV Cacheç”Ÿæˆç¤ºä¾‹ â­
â”‚
â”œâ”€â”€ CMakeLists.txt          # CMakeé…ç½®
â””â”€â”€ README.md               # æœ¬æ–‡ä»¶
```

---

## å¿«é€Ÿå¼€å§‹

### 1. ç¼–è¯‘é¡¹ç›®

```bash
cd tensor_cpp
mkdir -p build && cd build
cmake .. -DCMAKE_BUILD_TYPE=Release
make -j$(nproc)
```

ç¼–è¯‘å®Œæˆåï¼Œåœ¨ `build/` ç›®å½•ç”Ÿæˆä»¥ä¸‹å¯æ‰§è¡Œæ–‡ä»¶ï¼š
- `test_qwen3_logits` - Forward passæµ‹è¯•
- `test_qwen3_generate` - è‡ªå›å½’ç”Ÿæˆæµ‹è¯•
- `test_qwen3_generate_with_cache` - å¸¦KV Cacheçš„ç”Ÿæˆæµ‹è¯•
- `test_ops` - åŸºç¡€ç®—å­æµ‹è¯•
- `test_attention` - Attentionæµ‹è¯•
- `test_qwen3` - Qwen3åŸºç¡€æµ‹è¯•
- `test_qwen3_decode` - Decodeé˜¶æ®µæµ‹è¯•
- `test_qwen3_verify` - æ¨¡å‹éªŒè¯æµ‹è¯•
- `benchmark_qwen3` - æ€§èƒ½åŸºå‡†æµ‹è¯•
- `benchmark_attention` - Attentionæ€§èƒ½æµ‹è¯•
- `test_mpi_simple` - MPIæµ‹è¯•

### 2. è¿è¡Œç¯å¢ƒé…ç½®

**é‡è¦**: å¦‚æœä½¿ç”¨anacondaç¯å¢ƒï¼Œéœ€è¦è®¾ç½®ç³»ç»Ÿåº“è·¯å¾„ï¼š

```bash
export LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu:$LD_LIBRARY_PATH
```

æˆ–è€…åœ¨æ¯ä¸ªå‘½ä»¤å‰åŠ ä¸Šï¼š
```bash
LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu:$LD_LIBRARY_PATH ./test_qwen3_logits
```

---

## ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1ï¼šForward Pass (test_qwen3_logits) â­

**åŠŸèƒ½**: å¯¹å•ä¸ªtokenè¿›è¡Œå‰å‘ä¼ æ’­ï¼Œè¾“å‡ºè¯¦ç»†çš„logitsä¿¡æ¯ï¼Œç”¨äºè°ƒè¯•å’Œä¸PyTorchå¯¹æ¯”ã€‚

```bash
cd build
export LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu:$LD_LIBRARY_PATH
./test_qwen3_logits
```

**è¾“å‡ºç¤ºä¾‹**:
```
============================================================
  Qwen3 Logits Debugging Test
============================================================

Loading weights...
Weights loaded!

Input: [9707] (token for 'Hello')

Running forward pass...
Forward complete!

Hidden States (last layer, last token):
  Shape: (1, 1, 1024)
  Range: [-26.1674, 29.6104]
  Mean: -0.0723627
  Std: 2.58689

Computing logits...
Top 20 tokens:
  [0] token=21806 logit=8.1391
  [1] token=14582 logit=8.0768
  [2] token=15846 logit=7.6319
  [3] token=477 logit=7.5790
  ...

Logits statistics:
  Mean: -1.0940
  Std: 1.9828
  Min: -10.3701 (token 111386)
  Max: 8.1391 (token 21806)
```

**ä¿å­˜çš„æ–‡ä»¶**:
- `/tmp/cpp_hidden_states.bin` - éšè—å±‚è¾“å‡ºï¼ˆ1024ä¸ªfloatï¼‰
- `/tmp/cpp_last_hidden.bin` - æœ€åä¸€ä¸ªtokençš„éšè—çŠ¶æ€ï¼ˆ1024ä¸ªfloatï¼‰
- `/tmp/cpp_logits.bin` - å®Œæ•´çš„logitsï¼ˆ151936ä¸ªfloatï¼‰

**ç”¨é€”**:
- è°ƒè¯•æ¨¡å‹å®ç°
- ä¸PyTorchå®ç°å¯¹æ¯”
- éªŒè¯æ•°å€¼æ­£ç¡®æ€§

---

### ç¤ºä¾‹2ï¼šæ–‡æœ¬ç”Ÿæˆ (test_qwen3_generate)

**åŠŸèƒ½**: è‡ªå›å½’æ–‡æœ¬ç”Ÿæˆï¼Œä¸ä½¿ç”¨KV Cacheï¼ˆæ¯æ¬¡é‡æ–°å¤„ç†æ•´ä¸ªåºåˆ—ï¼‰ã€‚

```bash
cd build
export LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu:$LD_LIBRARY_PATH
./test_qwen3_generate
```

**è¾“å‡ºç¤ºä¾‹**:
```
============================================================
  Qwen3 Text Generation Test
============================================================

Test 1: "Hello"
Input tokens (9): 151644 872 198 9707 151645 198 151644 77091 198

Generating 12 tokens...

Step  1: token=151667  logit=28.46  time= 874 ms
Step  2: token=   198  logit=31.82  time= 853 ms
Step  3: token= 32313  logit=21.70  time= 821 ms
Step  4: token=    11  logit=25.31  time= 845 ms
...

Generation Summary:
  Total time: 12647 ms
  Tokens generated: 12
  Average time per token: 1053 ms
  Tokens per second: 0.95

Decoding output:
OUTPUT: 'user\nHello\nassistant\n\nOkay, the user said "Hello" and I'
```

**ç‰¹ç‚¹**:
- âœ… å®Œæ•´å®ç°ï¼Œæ˜“äºç†è§£
- âŒ æ€§èƒ½è¾ƒä½ï¼ˆæ¯æ¬¡forwardéƒ½å¤„ç†æ•´ä¸ªåºåˆ—ï¼‰
- â±ï¸ å¹³å‡ 1ç§’/token
- ğŸ“š é€‚åˆå­¦ä¹ ç”Ÿæˆæµç¨‹

---

### ç¤ºä¾‹3ï¼šæ–‡æœ¬ç”Ÿæˆ with KV Cache (test_qwen3_generate_with_cache) â­â­â­

**åŠŸèƒ½**: ä½¿ç”¨KV Cacheçš„è‡ªå›å½’æ–‡æœ¬ç”Ÿæˆï¼Œæ€§èƒ½æå‡çº¦**1.7å€**ã€‚

```bash
cd build
export LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu:$LD_LIBRARY_PATH
./test_qwen3_generate_with_cache
```

**è¾“å‡ºç¤ºä¾‹**:
```
============================================================
  Qwen3 Text Generation Test WITH KV CACHE
============================================================

Test 1: "Hello"
Input tokens (9): 151644 872 198 9707 151645 198 151644 77091 198

Initializing KV cache...
KV cache initialized!

Generating 12 tokens...

Phase: PREFILL (processing initial prompt)
  Prefill time: 907 ms
  Tokens processed: 9
  First predicted token: 151667 (logit=28.464)
  Cache initialized: 9 tokens

Phase: DECODE (generating tokens one by one)
  With KV cache, each step only processes 1 new token!

Step  2: token=  3553  logit=13.47  time= 608 ms  (cached_tokens=10)
Step  3: token= 75965  logit=13.16  time= 599 ms  (cached_tokens=11)
Step  4: token=  3342  logit=12.15  time= 591 ms  (cached_tokens=12)
...

Generation Summary:
  Total time: 6992 ms
  Tokens generated: 11
  Average time per token: 635 ms
  Tokens per second: 1.57
  Final cache size: 20 tokens
```

**æ€§èƒ½å¯¹æ¯”**:
| æ–¹æ³• | æ€»æ—¶é—´ | å¹³å‡æ—¶é—´/token | ååé‡ | åŠ é€Ÿæ¯” |
|------|--------|----------------|--------|--------|
| ä¸ç”¨KV Cache | 12497 ms | 1041 ms | 0.96 tokens/s | 1.0x |
| **ç”¨KV Cache** | **6610 ms** | **600 ms** | **1.66 tokens/s** | **1.74x** |

**ä¼˜åŠ¿**:
- âœ… æ€§èƒ½æå‡1.74å€
- âœ… å†…å­˜æ•ˆç‡æ›´é«˜
- âœ… é€‚åˆå®é™…åº”ç”¨
- âœ… ç»“æœå®Œå…¨ä¸€è‡´ï¼ˆå·²ä¿®å¤ç´¢å¼•bugï¼‰

---

## æ¨¡å‹è§„æ ¼

**Qwen3-0.6B**:
```
å±‚æ•° (num_layers): 28
éšè—å±‚ç»´åº¦ (hidden_size): 1024
Attention heads (num_attention_heads): 16
KV heads (num_key_value_heads): 8 (GQA - Grouped Query Attention)
Headç»´åº¦ (head_dim): 128
è¯æ±‡è¡¨å¤§å° (vocab_size): 151936
ä¸­é—´å±‚ç»´åº¦ (intermediate_size): 4096 (4 * hidden_size)
RMSNorm epsilon: 1e-6
```

---

## ä»£ç ç¤ºä¾‹

### Forward Pass

```cpp
#include "tensor_cpp/qwen3_loader.h"
#include "tensor_cpp/qwen3_ops.h"

using namespace tensor_cpp;
using namespace tensor_cpp::qwen3;

// åŠ è½½æ¨¡å‹
std::string model_path = "/media/song/LocalDisk/Storage/checkpoints/Qwen3-0.6B/model.safetensors";
Qwen3Weights weights = load_qwen3_weights(model_path);

// å‡†å¤‡è¾“å…¥
std::vector<long> input_ids = {9707};  // "Hello"
Shape input_shape({1, input_ids.size()});
TensorL input(input_ids, input_shape);

// Forward pass
Tensor hidden_states = qwen3::qwen3_forward(
    input,
    weights.embed_tokens,
    weights.layers,
    weights.norm_weight,
    weights.num_layers,
    weights.num_attention_heads,
    weights.num_key_value_heads,
    weights.head_dim,
    1e-6f  // epsilon for RMSNorm
);
// hidden_states: Shape(batch_size, seq_len, hidden_size)
//                Shape(1, 1, 1024)
```

### Generation with KV Cache

```cpp
#include "tensor_cpp/qwen3_loader.h"
#include "tensor_cpp/qwen3_ops.h"
#include "tensor_cpp/kv_cache.h"

using namespace tensor_cpp;
using namespace tensor_cpp::qwen3;

// åŠ è½½æ¨¡å‹
Qwen3Weights weights = load_qwen3_weights(model_path);

// åˆ›å»ºKV Cache
auto kv_cache = std::make_unique<KVCache>(
    weights.num_layers,          // 28 layers
    1,                            // batch_size
    weights.num_key_value_heads,  // 8 KV heads
    weights.head_dim,             // 128 head_dim
    4096                          // max_seq_len
);

// Phase 1: Prefill - å¤„ç†åˆå§‹prompt
std::vector<long> input_ids = {151644, 872, 198, 9707, 151645, 198, 151644, 77091, 198};
Shape input_shape({1, input_ids.size()});
TensorL input(input_ids, input_shape);

Tensor hidden_states = qwen3::qwen3_forward_with_cache(
    input,
    kv_cache.get(),
    weights.embed_tokens,
    weights.layers,
    weights.norm_weight,
    weights.num_layers,
    weights.num_attention_heads,
    weights.num_key_value_heads,
    weights.head_dim,
    1e-6f
);

// Phase 2: Decode - é€ä¸ªç”Ÿæˆtoken
std::vector<long> generated = input_ids;
for (int step = 0; step < max_new_tokens; ++step) {
    // å‡†å¤‡å•ä¸ªæ–°token
    std::vector<long> new_token = {generated.back()};
    TensorL new_input(new_token, Shape({1, 1}));

    // Forward with cache
    Tensor new_hidden = qwen3::qwen3_forward_with_cache(
        new_input,
        kv_cache.get(),
        weights.embed_tokens,
        weights.layers,
        weights.norm_weight,
        weights.num_layers,
        weights.num_attention_heads,
        weights.num_key_value_heads,
        weights.head_dim,
        1e-6f
    );

    // è®¡ç®—logits
    long next_token = predict_next_token(new_hidden, weights.lm_head);
    generated.push_back(next_token);

    // æ£€æŸ¥EOS
    if (next_token == 151645) break;
}
```

---

## æµ‹è¯•ç¨‹åºè¯´æ˜

### æ ¸å¿ƒæµ‹è¯•ç¨‹åº â­

è¿™ä¸‰ä¸ªç¨‹åºæ˜¯æœ€ä¸»è¦çš„ä½¿ç”¨ç¤ºä¾‹ï¼š

| ç¨‹åº | åŠŸèƒ½ | è¿è¡Œæ—¶é—´ | æ¨èåœºæ™¯ |
|------|------|----------|----------|
| `test_qwen3_logits` | Forward passï¼Œè¾“å‡ºè¯¦ç»†logits | ~900 ms | è°ƒè¯•ã€ä¸PyTorchå¯¹æ¯” |
| `test_qwen3_generate` | è‡ªå›å½’ç”Ÿæˆï¼ˆæ— cacheï¼‰ | ~13ç§’ (12 tokens) | ç†è§£ç”Ÿæˆæµç¨‹ |
| `test_qwen3_generate_with_cache` | è‡ªå›å½’ç”Ÿæˆï¼ˆæœ‰cacheï¼‰ | ~7ç§’ (12 tokens) | **å®é™…åº”ç”¨** â­â­â­ |

### å…¶ä»–æµ‹è¯•ç¨‹åº

**Qwen3ç›¸å…³**:
- `test_qwen3.cpp` - Qwen3åŸºç¡€æµ‹è¯•
- `test_qwen3_decode.cpp` - Decodeé˜¶æ®µä¸“é¡¹æµ‹è¯•
- `test_qwen3_verify.cpp` - æ¨¡å‹æ­£ç¡®æ€§éªŒè¯
- `benchmark_qwen3.cpp` - æ€§èƒ½åŸºå‡†æµ‹è¯•

**Attentionç›¸å…³**:
- `test_attention.cpp` - Attentionæœºåˆ¶æµ‹è¯•
- `test_streaming_attention.cpp` - Streaming Attentionæµ‹è¯•
- `benchmark_attention.cpp` - Attentionæ€§èƒ½æµ‹è¯•

**åŸºç¡€ç®—å­**:
- `test_ops.cpp` - Linear, RMSNorm, RoPE, SwiGLUç­‰ç®—å­æµ‹è¯•
- `test_mpi_simple.cpp` - MPIå¹¶è¡Œæµ‹è¯•

**è°ƒè¯•å·¥å…·**:
- `test_align_qwen3.cpp` - ä¸PyTorchå¯¹é½æµ‹è¯•
- `test_detailed_layer2.cpp` - é€å±‚è¯¦ç»†è¾“å‡º
- `test_layers_debug.cpp` - å±‚çº§è°ƒè¯•
- `torch_validation.cpp` - PyTorchéªŒè¯å·¥å…·

---

## ä¾èµ–

### å¿…éœ€
- C++17 ç¼–è¯‘å™¨ (g++ 7.0+ æˆ– clang++ 5.0+)
- CMake 3.16+
- OpenMP 4.5+ (é€šå¸¸ç¼–è¯‘å™¨è‡ªå¸¦)
- MPI 4.0+ (å¯é€‰ï¼Œç”¨äºMPIæµ‹è¯•)

### ç³»ç»Ÿè¦æ±‚
- **æ“ä½œç³»ç»Ÿ**: Linux (æµ‹è¯•ç¯å¢ƒï¼šUbuntu 22.04)
- **å†…å­˜**: è‡³å°‘4GBï¼ˆåŠ è½½Qwen3-0.6Bæ¨¡å‹éœ€è¦çº¦2.4GBï¼‰
- **ç£ç›˜**: çº¦2.4GB (model.safetensors)
- **æ¨¡å‹**: Qwen3-0.6B safetensorsæ ¼å¼

### å®‰è£…ä¾èµ– (Ubuntu/Debian)

```bash
sudo apt-get update
sudo apt-get install build-essential cmake
sudo apt-get install libomp-dev libopenmpi-dev

# å¦‚æœæ²¡æœ‰æ¨¡å‹ï¼Œéœ€è¦å®‰è£…transformerså’Œsafetensors
pip install transformers safetensors
```

---

## æ€§èƒ½æ•°æ®

### æµ‹è¯•ç¯å¢ƒ
- CPU: Intel Xeon (å…·ä½“å‹å·æœªæŒ‡å®š)
- ç¼–è¯‘å™¨: GCC 13.3.0
- ä¼˜åŒ–é€‰é¡¹: `-O3 -march=native`
- OpenMP: 4.5
- MPI: 4.0

### å®æµ‹æ€§èƒ½

**Prefillé˜¶æ®µ** (9 tokens):
- æ—¶é—´: 907 ms
- ååé‡: 9.9 tokens/s

**Decodeé˜¶æ®µ** (with KV Cache):
- å¹³å‡æ—¶é—´/token: 635 ms
- ååé‡: 1.57 tokens/s
- åŠ é€Ÿæ¯”: 1.8x (ç›¸æ¯”ä¸ç”¨cache)

**å¯¹æ¯”: ä¸ç”¨KV Cache**:
- å¹³å‡æ—¶é—´/token: 1053 ms
- ååé‡: 0.95 tokens/s

### æ€§èƒ½ç“¶é¢ˆåˆ†æ

1. **å†…å­˜å¸¦å®½é™åˆ¶**: CPUä¸ŠLLMæ¨ç†çš„ä¸»è¦ç“¶é¢ˆ
2. **æœªä¼˜åŒ–çŸ©é˜µä¹˜æ³•**: å½“å‰ä½¿ç”¨æœ´ç´ å®ç°
3. **å•çº¿ç¨‹batch**: å½“å‰batch_size=1

### ä¼˜åŒ–æ–¹å‘

- [ ] ä½¿ç”¨BLASåº“ä¼˜åŒ–çŸ©é˜µä¹˜æ³•
- [ ] SIMDæŒ‡ä»¤ä¼˜åŒ–ï¼ˆAVX-512ï¼‰
- [ ] INT8/FP16é‡åŒ–
- [ ] å¤šçº¿ç¨‹batchå¤„ç†
- [ ] æ›´å¥½çš„å†…å­˜è®¿é—®æ¨¡å¼

---

## å¸¸è§é—®é¢˜

### Q: è¿è¡Œæ—¶æç¤º "GLIBCXX_3.4.32 not found"ï¼Ÿ
A: anacondaç¯å¢ƒçš„libstdc++ç‰ˆæœ¬é—®é¢˜ã€‚è®¾ç½®ç³»ç»Ÿåº“è·¯å¾„ï¼š
```bash
export LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu:$LD_LIBRARY_PATH
```

### Q: æ¨¡å‹æ–‡ä»¶æ‰¾ä¸åˆ°ï¼Ÿ
A: ç¡®ä¿æ¨¡å‹è·¯å¾„æ­£ç¡®ï¼š
```bash
/media/song/LocalDisk/Storage/checkpoints/Qwen3-0.6B/model.safetensors
```

å¦‚éœ€ä¿®æ”¹è·¯å¾„ï¼Œç¼–è¾‘æµ‹è¯•æ–‡ä»¶ä¸­çš„ `model_path` å˜é‡ã€‚

### Q: ç”Ÿæˆçš„æ–‡æœ¬æœ‰é‡å¤ï¼Ÿ
A: å½“å‰ä½¿ç”¨è´ªå©ªè§£ç ï¼ˆgreedy decodingï¼‰ï¼Œå®¹æ˜“äº§ç”Ÿé‡å¤ã€‚æ”¹è¿›æ–¹æ³•ï¼š
- æ·»åŠ æ¸©åº¦é‡‡æ ·
- ä½¿ç”¨Top-ké‡‡æ ·
- ä½¿ç”¨Nucleus sampling

### Q: å¦‚ä½•æ”¹å˜ç”Ÿæˆå‚æ•°ï¼Ÿ
A: ç¼–è¾‘æµ‹è¯•æ–‡ä»¶ï¼Œä¿®æ”¹ä»¥ä¸‹å‚æ•°ï¼š
```cpp
size_t max_new_tokens = 12;  // ç”Ÿæˆçš„tokenæ•°é‡
float temperature = 1.0f;    // æ¸©åº¦ï¼ˆéœ€è¦è‡ªå·±å®ç°ï¼‰
int top_k = 50;               // Top-ké‡‡æ ·ï¼ˆéœ€è¦è‡ªå·±å®ç°ï¼‰
```

### Q: ç¼–è¯‘æ—¶å‡ºç°MPIç›¸å…³é”™è¯¯ï¼Ÿ
A: MPIæ˜¯å¯é€‰çš„ã€‚å¦‚æœä¸éœ€è¦MPIæµ‹è¯•ï¼Œå¯ä»¥ä¿®æ”¹CMakeLists.txtæ³¨é‡Šæ‰MPIç›¸å…³éƒ¨åˆ†ã€‚

---

## ä¸PyTorchå¯¹æ¯”

### æ•°å€¼éªŒè¯

å¯ä»¥ä½¿ç”¨æä¾›çš„Pythonè„šæœ¬éªŒè¯C++å®ç°çš„æ­£ç¡®æ€§ï¼š

```python
import torch
from safetensors.torch import load_file

# åŠ è½½æƒé‡
weights = load_file("/media/song/LocalDisk/Storage/checkpoints/Qwen3-0.6B/model.safetensors")

# è¿è¡ŒC++ç¨‹åº
# ./test_qwen3_logits

# å¯¹æ¯”C++è¾“å‡ºçš„binæ–‡ä»¶
cpp_hidden = np.fromfile("/tmp/cpp_hidden_states.bin", dtype=np.float32)
cpp_logits = np.fromfile("/tmp/cpp_logits.bin", dtype=np.float32)

# åœ¨PyTorchä¸­è¿è¡Œç›¸åŒè¾“å…¥
# ... (å…·ä½“éªŒè¯ä»£ç è§tests/torch_validation.cpp)
```

---

## å¼€å‘è®¡åˆ’

### çŸ­æœŸ
- [ ] æ·»åŠ æ¸©åº¦é‡‡æ ·
- [ ] æ·»åŠ Top-kå’ŒNucleus sampling
- [ ] æ”¯æŒbatch_size > 1

### ä¸­æœŸ
- [ ] ä½¿ç”¨BLASåº“ä¼˜åŒ–çŸ©é˜µä¹˜æ³•
- [ ] æ·»åŠ INT8é‡åŒ–æ”¯æŒ
- [ ] ä¼˜åŒ–KV Cacheå†…å­˜å¸ƒå±€

### é•¿æœŸ
- [ ] æ”¯æŒæ›´å¤šæ¨¡å‹ï¼ˆLlama, Mistralç­‰ï¼‰
- [ ] åˆ†å¸ƒå¼æ¨ç†
- [ ] GPUå®ç°ï¼ˆCUDAï¼‰

---

## è®¸å¯è¯

MIT License

---

## ç›¸å…³èµ„æº

- [Qwen3-0.6Bæ¨¡å‹](https://huggingface.co/Qwen/Qwen3-0.6B)
- [Safetensorsæ–‡æ¡£](https://huggingface.co/docs/safetensors)
- [ä¸»é¡¹ç›®README](../README.md)
- [å¹¶è¡Œè®¡ç®—è¯¾ç¨‹æŠ¥å‘Š](../REPORT.md)
